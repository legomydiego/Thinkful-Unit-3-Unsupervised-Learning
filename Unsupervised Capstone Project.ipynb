{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting character dialogue from The Matrix\n",
    "\n",
    "The goal of this project is to use supervised and unsupervised machine learning to predict a character's dialogue. The source material is the movie The Matrix. \n",
    "\n",
    "For the unsupervised learning section, the goal is to create clusters corresponding to the major characters of the film and try to identify which character corresponds to each cluster based on the dialogue centered around it. Different models will be used to vectorize the lines for each character and model them in order to make predictions. From the terms grouped around each cluster, I'll try to figure out which character is more likely to have said those words based on my knowledge of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/diegofvargas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/diegofvargas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Remove the location of each scene, they're in between parenthesis\n",
    "    text = re.sub(r'[\\([a-zA-Z]*.[a-zA-Z]*\\)','',raw)\n",
    "    #text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "The_Matrix = open('The Matrix Script.txt','r') \n",
    "raw=The_Matrix.read()\n",
    "The_Matrix.close()\n",
    "script = text_cleaner(raw)\n",
    "tokens = nltk.word_tokenize(script)\n",
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "sentences = []\n",
    "for line in script.splitlines():\n",
    "    if ':' in line:\n",
    "        characters.append(line.split(':')[0])\n",
    "        sentences.append(line.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_df = pd.DataFrame(np.column_stack([characters, sentences]), columns = ['character','sentences']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Is everything in place?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>You weren't supposed to relieve me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>I know, but I want to take your shift.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>You like watching him, don't you?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                sentences\n",
       "0    Cypher                                    Yeah.\n",
       "1   Trinity                  Is everything in place?\n",
       "2    Cypher      You weren't supposed to relieve me.\n",
       "3   Trinity   I know, but I want to take your shift.\n",
       "4    Cypher       You like watching him, don't you? "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cypher' 'Trinity' 'Cop' 'Agent Smith' 'Lieutenant' 'Morpheus'\n",
      " 'Agent Brown' 'Agent Jones' 'Neo' 'Choi' 'DuJour' 'Mr. Rhineheart'\n",
      " 'FedEx man' 'Switch' 'Apoc' 'Dozer' 'Tank' 'Mouse' 'Priestess'\n",
      " 'Spoon boy' 'Oracle' 'Police' 'Guard 1' 'Guard 2' 'Soldier' 'Pilot' 'Man'\n",
      " 'The One']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(script_df['character'].unique())\n",
    "print(len(script_df['character'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will focus on the main 4 characters since they have the most lines, making their data richer and better for analysis\n",
    "main_chars_df = script_df[script_df.character.isin(['Neo', 'Trinity','Morpheus','Agent Smith'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegofvargas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# tokenization\n",
    "tokenized_script = main_chars_df['sentences'].apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words\n",
    "tokenized_script = tokenized_script.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# de-tokenization\n",
    "detokenized_script = []\n",
    "for i in range(len(main_chars_df)):\n",
    "    t = ' '.join(tokenized_script.reset_index().iloc[i]['sentences'])\n",
    "    detokenized_script.append(t)\n",
    "\n",
    "main_chars_df['clean_sentences'] = detokenized_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>sentences</th>\n",
       "      <th>clean_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Is everything in place?</td>\n",
       "      <td>Is everything place?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>I know, but I want to take your shift.</td>\n",
       "      <td>I know, I want take shift.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Don't be ridiculous.</td>\n",
       "      <td>Don't ridiculous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Morpheus believes he is the one.</td>\n",
       "      <td>Morpheus believes one.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>It doesn't matter what I believe.</td>\n",
       "      <td>It matter I believe.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character                                sentences  \\\n",
       "1    Trinity                  Is everything in place?   \n",
       "3    Trinity   I know, but I want to take your shift.   \n",
       "6    Trinity                     Don't be ridiculous.   \n",
       "8    Trinity         Morpheus believes he is the one.   \n",
       "10   Trinity        It doesn't matter what I believe.   \n",
       "\n",
       "               clean_sentences  \n",
       "1         Is everything place?  \n",
       "3   I know, I want take shift.  \n",
       "6            Don't ridiculous.  \n",
       "8       Morpheus believes one.  \n",
       "10        It matter I believe.  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 776)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "max_features= 5000,\n",
    "max_df = 0.5, \n",
    "smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(main_chars_df['clean_sentences'])\n",
    "\n",
    "X.shape # check shape of the document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SVD represent terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=1000, random_state=101)\n",
    "\n",
    "svd_model.fit(X)\n",
    "\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character 0: \n",
      "know\n",
      "neo\n",
      "morpheus\n",
      "want\n",
      "trinity\n",
      "going\n",
      "hello\n",
      "yes\n",
      "trying\n",
      "come\n",
      "tell\n",
      "looking\n",
      "matrix\n",
      "ready\n",
      "like\n",
      "ve\n",
      "believe\n",
      "line\n",
      "make\n",
      "world\n",
      "Character 1: \n",
      "morpheus\n",
      "neo\n",
      "going\n",
      "don\n",
      "ready\n",
      "oracle\n",
      "believed\n",
      "told\n",
      "alive\n",
      "gave\n",
      "believes\n",
      "convinced\n",
      "place\n",
      "happened\n",
      "make\n",
      "come\n",
      "sacrificed\n",
      "kill\n",
      "way\n",
      "gotcha\n",
      "Character 2: \n",
      "yes\n",
      "neo\n",
      "hell\n",
      "beginning\n",
      "old\n",
      "elevator\n",
      "slowly\n",
      "yeah\n",
      "mr\n",
      "clear\n",
      "perfectly\n",
      "rhineheart\n",
      "run\n",
      "come\n",
      "coming\n",
      "looking\n",
      "time\n",
      "hello\n",
      "unfortunately\n",
      "watching\n",
      "Character 3: \n",
      "neo\n",
      "hello\n",
      "come\n",
      "easy\n",
      "hurry\n",
      "watching\n",
      "like\n",
      "true\n",
      "matters\n",
      "trust\n",
      "looking\n",
      "tell\n",
      "run\n",
      "protection\n",
      "truth\n",
      "necessary\n",
      "say\n",
      "answer\n",
      "breathe\n",
      "said\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(svd_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "    print(\"Character \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my knowledge of the movie, I can sort of tell what character the clusters correspond to. \n",
    "\n",
    "Neo seems to be character 2, given that he is the only one to refer to Mr. rhineheart who was his boss in the matrix and the prominence of hell, which he used frequently to express excitement.\n",
    "\n",
    "Character 3 seems to be Morpheus since the top word is Neo, who he mostly interacts with. He also says hello a lot since he is introducing Neo and the audience to the real world.\n",
    "\n",
    "Character 1 is Trinity, because her main two interactions are with Morpheus and Neo, which are her top two words. There are also words like alive and believes that relate to the scene when Trinity revives Neo.\n",
    "\n",
    "Character 0 must be Agent Smith. The top terms are Neo, Morpheus and Trinity, who are the main culprits in his eyes. Wouldn't make sense for any character besides Neo to have their own name as a top term, because he says his new identity a lot as he's discovering the new world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf_model = NMF(n_components=4, init='random', random_state=101)\n",
    "W = nmf_model.fit_transform(X)\n",
    "H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character 0: \n",
      "morpheus\n",
      "going\n",
      "don\n",
      "believed\n",
      "ready\n",
      "alive\n",
      "oracle\n",
      "gave\n",
      "told\n",
      "believes\n",
      "convinced\n",
      "make\n",
      "place\n",
      "happened\n",
      "kill\n",
      "gotcha\n",
      "great\n",
      "meet\n",
      "traced\n",
      "sacrificed\n",
      "Character 1: \n",
      "trinity\n",
      "believe\n",
      "help\n",
      "oracle\n",
      "focus\n",
      "going\n",
      "hit\n",
      "make\n",
      "base\n",
      "cracked\n",
      "irs\n",
      "real\n",
      "ve\n",
      "worry\n",
      "matrix\n",
      "world\n",
      "welcome\n",
      "tank\n",
      "little\n",
      "beginning\n",
      "Character 2: \n",
      "neo\n",
      "yes\n",
      "come\n",
      "hello\n",
      "going\n",
      "like\n",
      "tell\n",
      "want\n",
      "looking\n",
      "easy\n",
      "watching\n",
      "true\n",
      "hurry\n",
      "matters\n",
      "trust\n",
      "run\n",
      "ready\n",
      "ve\n",
      "trying\n",
      "coming\n",
      "Character 3: \n",
      "know\n",
      "want\n",
      "trying\n",
      "hope\n",
      "line\n",
      "lot\n",
      "dead\n",
      "shift\n",
      "suggest\n",
      "looking\n",
      "matrix\n",
      "world\n",
      "went\n",
      "ve\n",
      "exactly\n",
      "hello\n",
      "feel\n",
      "coincidence\n",
      "does\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "for i, comp in enumerate(H):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "    print(\"Character \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF wasn't as effective as SVD at clustering each character from the movie. The terms in each cluster aren't as helpful in determining which character is represented, so for this data set SVD is a more appropiate technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
