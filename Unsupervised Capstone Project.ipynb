{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting character dialogue from The Matrix\n",
    "\n",
    "The goal of this project is to use supervised and unsupervised machine learning to predict a character's dialogue. The source material is the movie The Matrix. \n",
    "\n",
    "For the unsupervised learning section, the goal is to create clusters corresponding to the major characters of the film and try to identify which character corresponds to each cluster based on the dialogue centered around it. Different models will be used to vectorize the lines for each character and model them in order to make predictions. From the terms grouped around each cluster, I'll try to figure out which character is more likely to have said those words based on my knowledge of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/diegofvargas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/diegofvargas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /home/diegofvargas/anaconda3/lib/python3.7/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/diegofvargas/anaconda3/lib/python3.7/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/diegofvargas/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Remove the location of each scene, they're in between parenthesis\n",
    "    text = re.sub(r'[\\([a-zA-Z]*.[a-zA-Z]*\\)','',raw)\n",
    "    #text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "The_Matrix = open('The Matrix Script.txt','r') \n",
    "raw=The_Matrix.read()\n",
    "The_Matrix.close()\n",
    "script = text_cleaner(raw)\n",
    "tokens = nltk.word_tokenize(script)\n",
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "sentences = []\n",
    "for line in script.splitlines():\n",
    "    if ':' in line:\n",
    "        characters.append(line.split(':')[0])\n",
    "        sentences.append(line.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_df = pd.DataFrame(np.column_stack([characters, sentences]), columns = ['character','sentences']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Is everything in place?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>You weren't supposed to relieve me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>I know, but I want to take your shift.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>You like watching him, don't you?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                sentences\n",
       "0    Cypher                                    Yeah.\n",
       "1   Trinity                  Is everything in place?\n",
       "2    Cypher      You weren't supposed to relieve me.\n",
       "3   Trinity   I know, but I want to take your shift.\n",
       "4    Cypher       You like watching him, don't you? "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cypher' 'Trinity' 'Cop' 'Agent Smith' 'Lieutenant' 'Morpheus'\n",
      " 'Agent Brown' 'Agent Jones' 'Neo' 'Choi' 'DuJour' 'Mr. Rhineheart'\n",
      " 'FedEx man' 'Switch' 'Apoc' 'Dozer' 'Tank' 'Mouse' 'Priestess'\n",
      " 'Spoon boy' 'Oracle' 'Police' 'Guard 1' 'Guard 2' 'Soldier' 'Pilot' 'Man'\n",
      " 'The One']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(script_df['character'].unique())\n",
    "print(len(script_df['character'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will focus on the main 4 characters since they have the most lines, making their data richer and better for analysis\n",
    "main_chars_df = script_df[script_df.character.isin(['Neo', 'Trinity','Morpheus','Agent Smith'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegofvargas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# tokenization\n",
    "tokenized_script = main_chars_df['sentences'].apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words\n",
    "tokenized_script = tokenized_script.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# de-tokenization\n",
    "detokenized_script = []\n",
    "for i in range(len(main_chars_df)):\n",
    "    t = ' '.join(tokenized_script.reset_index().iloc[i]['sentences'])\n",
    "    detokenized_script.append(t)\n",
    "\n",
    "main_chars_df['clean_sentences'] = detokenized_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>sentences</th>\n",
       "      <th>clean_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Is everything in place?</td>\n",
       "      <td>Is everything place?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>I know, but I want to take your shift.</td>\n",
       "      <td>I know, I want take shift.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Don't be ridiculous.</td>\n",
       "      <td>Don't ridiculous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Morpheus believes he is the one.</td>\n",
       "      <td>Morpheus believes one.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>It doesn't matter what I believe.</td>\n",
       "      <td>It matter I believe.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character                                sentences  \\\n",
       "1    Trinity                  Is everything in place?   \n",
       "3    Trinity   I know, but I want to take your shift.   \n",
       "6    Trinity                     Don't be ridiculous.   \n",
       "8    Trinity         Morpheus believes he is the one.   \n",
       "10   Trinity        It doesn't matter what I believe.   \n",
       "\n",
       "               clean_sentences  \n",
       "1         Is everything place?  \n",
       "3   I know, I want take shift.  \n",
       "6            Don't ridiculous.  \n",
       "8       Morpheus believes one.  \n",
       "10        It matter I believe.  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 776)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "max_features= 5000,\n",
    "max_df = 0.5, \n",
    "smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(main_chars_df['clean_sentences'])\n",
    "\n",
    "X.shape # check shape of the document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SVD represent terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=1000, random_state=101)\n",
    "\n",
    "svd_model.fit(X)\n",
    "\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character 0: \n",
      "know\n",
      "neo\n",
      "morpheus\n",
      "want\n",
      "trinity\n",
      "going\n",
      "hello\n",
      "yes\n",
      "trying\n",
      "come\n",
      "tell\n",
      "looking\n",
      "matrix\n",
      "ready\n",
      "like\n",
      "ve\n",
      "believe\n",
      "line\n",
      "make\n",
      "world\n",
      "Character 1: \n",
      "morpheus\n",
      "neo\n",
      "going\n",
      "don\n",
      "ready\n",
      "oracle\n",
      "believed\n",
      "told\n",
      "alive\n",
      "gave\n",
      "believes\n",
      "convinced\n",
      "place\n",
      "happened\n",
      "make\n",
      "come\n",
      "sacrificed\n",
      "kill\n",
      "way\n",
      "gotcha\n",
      "Character 2: \n",
      "yes\n",
      "neo\n",
      "hell\n",
      "beginning\n",
      "old\n",
      "elevator\n",
      "slowly\n",
      "yeah\n",
      "mr\n",
      "clear\n",
      "perfectly\n",
      "rhineheart\n",
      "run\n",
      "come\n",
      "coming\n",
      "looking\n",
      "time\n",
      "hello\n",
      "unfortunately\n",
      "watching\n",
      "Character 3: \n",
      "neo\n",
      "hello\n",
      "come\n",
      "easy\n",
      "hurry\n",
      "watching\n",
      "like\n",
      "true\n",
      "matters\n",
      "trust\n",
      "looking\n",
      "tell\n",
      "run\n",
      "protection\n",
      "truth\n",
      "necessary\n",
      "say\n",
      "answer\n",
      "breathe\n",
      "said\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(svd_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "    print(\"Character \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my knowledge of the movie, I can sort of tell what character the clusters correspond to. \n",
    "\n",
    "Neo seems to be character 2, given that he is the only one to refer to Mr. rhineheart who was his boss in the matrix and the prominence of hell, which he used frequently to express excitement.\n",
    "\n",
    "Character 3 seems to be Morpheus since the top word is Neo, who he mostly interacts with. He also says hello a lot since he is introducing Neo and the audience to the real world.\n",
    "\n",
    "Character 1 is Trinity, because her main two interactions are with Morpheus and Neo, which are her top two words. There are also words like alive and believes that relate to the scene when Trinity revives Neo.\n",
    "\n",
    "Character 0 must be Agent Smith. The top terms are Neo, Morpheus and Trinity, who are the main culprits in his eyes. Wouldn't make sense for any character besides Neo to have their own name as a top term, because he says his new identity a lot as he's discovering the new world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf_model = NMF(n_components=4, init='random', random_state=101)\n",
    "W = nmf_model.fit_transform(X)\n",
    "H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character 0: \n",
      "morpheus\n",
      "going\n",
      "don\n",
      "believed\n",
      "ready\n",
      "alive\n",
      "oracle\n",
      "gave\n",
      "told\n",
      "believes\n",
      "convinced\n",
      "make\n",
      "place\n",
      "happened\n",
      "kill\n",
      "gotcha\n",
      "great\n",
      "meet\n",
      "traced\n",
      "sacrificed\n",
      "Character 1: \n",
      "trinity\n",
      "believe\n",
      "help\n",
      "oracle\n",
      "focus\n",
      "going\n",
      "hit\n",
      "make\n",
      "base\n",
      "cracked\n",
      "irs\n",
      "real\n",
      "ve\n",
      "worry\n",
      "matrix\n",
      "world\n",
      "welcome\n",
      "tank\n",
      "little\n",
      "beginning\n",
      "Character 2: \n",
      "neo\n",
      "yes\n",
      "come\n",
      "hello\n",
      "going\n",
      "like\n",
      "tell\n",
      "want\n",
      "looking\n",
      "easy\n",
      "watching\n",
      "true\n",
      "hurry\n",
      "matters\n",
      "trust\n",
      "run\n",
      "ready\n",
      "ve\n",
      "trying\n",
      "coming\n",
      "Character 3: \n",
      "know\n",
      "want\n",
      "trying\n",
      "hope\n",
      "line\n",
      "lot\n",
      "dead\n",
      "shift\n",
      "suggest\n",
      "looking\n",
      "matrix\n",
      "world\n",
      "went\n",
      "ve\n",
      "exactly\n",
      "hello\n",
      "feel\n",
      "coincidence\n",
      "does\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "for i, comp in enumerate(H):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "    print(\"Character \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF wasn't as effective as SVD at clustering each character from the movie. The terms in each cluster aren't as helpful in determining which character is represented, so for this data set SVD is a more appropiate technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "Next goal is to split the sentences into a column for each word and run various models to try to predict what character is more likely to have said a certain word. As of now, I'm using the entire dataset, but if it is too inaccurate will only include the major 4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>sentences</th>\n",
       "      <th>clean_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>Yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>Is everything in place?</td>\n",
       "      <td>Is everything place?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>You weren't supposed to relieve me.</td>\n",
       "      <td>You supposed relieve me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trinity</td>\n",
       "      <td>I know, but I want to take your shift.</td>\n",
       "      <td>I know, I want take shift.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cypher</td>\n",
       "      <td>You like watching him, don't you?</td>\n",
       "      <td>You like watching him, you?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                sentences  \\\n",
       "0    Cypher                                    Yeah.   \n",
       "1   Trinity                  Is everything in place?   \n",
       "2    Cypher      You weren't supposed to relieve me.   \n",
       "3   Trinity   I know, but I want to take your shift.   \n",
       "4    Cypher       You like watching him, don't you?    \n",
       "\n",
       "               clean_sentences  \n",
       "0                        Yeah.  \n",
       "1         Is everything place?  \n",
       "2     You supposed relieve me.  \n",
       "3   I know, I want take shift.  \n",
       "4  You like watching him, you?  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename df to work in this context\n",
    "supervised_df = script_df\n",
    "supervised_df['character'] = np.where(supervised_df['character']=='Neo','Neo','Not Neo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "tokenized_script = supervised_df['sentences'].apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words\n",
    "tokenized_script = tokenized_script.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# de-tokenization\n",
    "detokenized_script = []\n",
    "for i in range(len(supervised_df)):\n",
    "    t = ' '.join(tokenized_script.reset_index().iloc[i]['sentences'])\n",
    "    detokenized_script.append(t)\n",
    "\n",
    "supervised_df['clean_sentences'] = detokenized_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of all the words in the script, after being cleaned of stop words\n",
    "words = []\n",
    "for sentence in supervised_df['clean_sentences'].apply(lambda x: x.split()):\n",
    "    for term in sentence:\n",
    "        words.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataframe for the words in the script and initializing with values at 0\n",
    "words_df = pd.DataFrame(columns=words)\n",
    "words_df['character'] = supervised_df['character']\n",
    "words_df.loc[:,words] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the row with word counts.\n",
    "for word in words:\n",
    "    words_df.loc[i, word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yeah.</th>\n",
       "      <th>Is</th>\n",
       "      <th>everything</th>\n",
       "      <th>place?</th>\n",
       "      <th>You</th>\n",
       "      <th>supposed</th>\n",
       "      <th>relieve</th>\n",
       "      <th>me.</th>\n",
       "      <th>I</th>\n",
       "      <th>know,</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>anything</th>\n",
       "      <th>possible.</th>\n",
       "      <th>Where</th>\n",
       "      <th>go</th>\n",
       "      <th>choice</th>\n",
       "      <th>I</th>\n",
       "      <th>leave</th>\n",
       "      <th>you.</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Neo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Neo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Yeah. Is everything place? You supposed relieve me.  I know,    ...     \\\n",
       "0     0  0          0      0   0        0       0   0  0     0    ...      \n",
       "1     0  0          0      0   0        0       0   0  0     0    ...      \n",
       "2     0  0          0      0   0        0       0   0  0     0    ...      \n",
       "3     0  0          0      0   0        0       0   0  0     0    ...      \n",
       "4     0  0          0      0   0        0       0   0  0     0    ...      \n",
       "\n",
       "  world anything possible. Where go choice  I leave you. character  \n",
       "0     0        0         0     0  0      0  0     0    0   Not Neo  \n",
       "1     0        0         0     0  0      0  0     0    0   Not Neo  \n",
       "2     0        0         0     0  0      0  0     0    0   Not Neo  \n",
       "3     0        0         0     0  0      0  0     0    0   Not Neo  \n",
       "4     0        0         0     0  0      0  0     0    0   Not Neo  \n",
       "\n",
       "[5 rows x 4706 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA to reduce features to 10 components, since the dataframe so wide\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "X = np.array(words_df.drop(['character'], 1))\n",
    "Y = words_df['character']\n",
    "X_balanced, Y_balanced = smt.fit_sample(X, Y)\n",
    "X_pca = PCA(10).fit_transform(X_balanced)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y_balanced, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Neo    321\n",
       "Neo        120\n",
       "Name: character, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(642, 10) (642,)\n",
      "Training set score: 0.5077881619937694\n",
      "Test set score: 0.4855072463768116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Neo       0.49      1.00      0.65       134\n",
      "    Not Neo       0.00      0.00      0.00       142\n",
      "\n",
      "avg / total       0.24      0.49      0.32       276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegofvargas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[134,   0],\n",
       "       [142,   0]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('Test set score:', lr.score(X_test, y_test))\n",
    "lr_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test, lr_pred))\n",
    "confusion_matrix(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.4937694704049844\n",
      "Test set score: 0.5144927536231884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Neo       0.49      1.00      0.65       134\n",
      "    Not Neo       0.00      0.00      0.00       142\n",
      "\n",
      "avg / total       0.24      0.49      0.32       276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegofvargas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[134,   0],\n",
       "       [142,   0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier(class_weight=\"balanced\")\n",
    "rfc.fit(X_train, y_train)\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('Test set score:', rfc.score(X_test, y_test))\n",
    "rfc_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test, rfc_pred))\n",
    "confusion_matrix(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.5077881619937694\n",
      "Test set score: 0.4855072463768116\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Neo       0.49      1.00      0.65       134\n",
      "    Not Neo       0.00      0.00      0.00       142\n",
      "\n",
      "avg / total       0.24      0.49      0.32       276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegofvargas/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[134,   0],\n",
       "       [142,   0]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('Test set score:', clf.score(X_test, y_test))\n",
    "clf_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test, clf_pred))\n",
    "confusion_matrix(y_test, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
